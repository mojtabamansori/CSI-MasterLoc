{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-14T15:08:40.798573Z",
     "start_time": "2025-09-14T15:08:39.995743Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "def csi_txt_to_excel(txt_path, out_dir=None, expand_data=False, max_data_cols=0):\n",
    "    \"\"\"\n",
    "    Convert concatenated CSI text into an Excel .xlsx file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    txt_path : str\n",
    "        Path to the input .txt file.\n",
    "    out_dir : str or None\n",
    "        Writable directory for the output .xlsx. If None, the function auto-selects:\n",
    "        - same directory as txt_path if writable\n",
    "        - '/kaggle/working' if available and writable\n",
    "        - current working directory otherwise\n",
    "    expand_data : bool\n",
    "        If True, expand the values inside data=[...] into separate columns (Data0, Data1, ...).\n",
    "        If False, keep the full list as a single string in column 'Data'.\n",
    "    max_data_cols : int\n",
    "        Max number of data columns to create when expand_data=True.\n",
    "        0 means auto-cap to Excel's column limit (up to 16,384 minus metadata columns).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Absolute path to the saved .xlsx file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Read the entire file\n",
    "    with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # Normalize escaped newlines in case the file is one long line like \"...]\\nCSI_DATA...\"\n",
    "    content = content.replace(\"\\\\n\", \"\\n\")\n",
    "\n",
    "    # Split into records; keep 'CSI_DATA,' at the start of each chunk\n",
    "    chunks = re.split(r'(?=CSI_DATA,)', content)\n",
    "    rows = []\n",
    "\n",
    "    for rec in chunks:\n",
    "        rec = rec.strip()\n",
    "        if not rec.startswith(\"CSI_DATA,\"):\n",
    "            continue\n",
    "\n",
    "        # Extract MAC: token right after \"CSI_DATA,\"\n",
    "        m_mac = re.search(r'^CSI_DATA,([^,]+)', rec)\n",
    "        mac = m_mac.group(1).strip() if m_mac else \"\"\n",
    "\n",
    "        # Extract timestamp after \"Now=\"\n",
    "        m_time = re.search(r'Now=\\s*([0-9\\-]{10}\\s[0-9:\\.]{8,})', rec)\n",
    "        timestamp = m_time.group(1).strip() if m_time else \"\"\n",
    "\n",
    "        # Extract data list inside brackets\n",
    "        m_data = re.search(r'data=\\[([^\\]]*)\\]', rec)\n",
    "        data_str = m_data.group(1).strip() if m_data else \"\"\n",
    "        data_list = [s.strip() for s in data_str.split(\",\")] if data_str else []\n",
    "\n",
    "        row = {\"MAC\": mac, \"Timestamp\": timestamp, \"Data\": data_str}\n",
    "\n",
    "        if expand_data:\n",
    "            # Determine max columns we can safely create for Excel\n",
    "            if max_data_cols <= 0:\n",
    "                # Excel limit is 16,384 columns; we already have 3 meta columns\n",
    "                max_cols_possible = 16384 - 3\n",
    "            else:\n",
    "                max_cols_possible = max_data_cols\n",
    "\n",
    "            for i, val in enumerate(data_list[:max_cols_possible]):\n",
    "                row[f\"Data{i}\"] = val\n",
    "\n",
    "            # Inform if truncated\n",
    "            if len(data_list) > max_cols_possible:\n",
    "                row[\"Data_Truncated\"] = f\"{len(data_list) - max_cols_possible} values truncated\"\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    # Build DataFrame\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # Helper to test if a directory is writable\n",
    "    def is_writable(dirpath: str) -> bool:\n",
    "        try:\n",
    "            test_path = os.path.join(dirpath, \".write_test\")\n",
    "            with open(test_path, \"w\") as tmp:\n",
    "                tmp.write(\"ok\")\n",
    "            os.remove(test_path)\n",
    "            return True\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "    # Decide output directory\n",
    "    src_dir = os.path.dirname(os.path.abspath(txt_path))\n",
    "    if out_dir:\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        target_dir = out_dir\n",
    "    elif is_writable(src_dir):\n",
    "        target_dir = src_dir\n",
    "    elif os.path.isdir(\"/kaggle/working\") and is_writable(\"/kaggle/working\"):\n",
    "        target_dir = \"/kaggle/working\"\n",
    "    else:\n",
    "        target_dir = os.getcwd()\n",
    "\n",
    "    # Build output path\n",
    "    base_name = os.path.splitext(os.path.basename(txt_path))[0]\n",
    "    excel_path = os.path.join(target_dir, base_name + \".xlsx\")\n",
    "\n",
    "    # Save to Excel\n",
    "    df.to_excel(excel_path, index=False)\n",
    "\n",
    "    return os.path.abspath(excel_path)\n",
    "\n",
    "\n",
    "# Example usage (auto-saves to /kaggle/working since /kaggle/input is read-only):\n",
    "paths = ['csi1/15-41-51-299.txt']\n",
    "for i in paths:\n",
    "    out_path = csi_txt_to_excel(i)\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'csi1/15-41-51-299.txt'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 118\u001B[0m\n\u001B[0;32m    116\u001B[0m paths \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcsi1/15-41-51-299.txt\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m    117\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m paths:\n\u001B[1;32m--> 118\u001B[0m     out_path \u001B[38;5;241m=\u001B[39m csi_txt_to_excel(i)\n",
      "Cell \u001B[1;32mIn[1], line 32\u001B[0m, in \u001B[0;36mcsi_txt_to_excel\u001B[1;34m(txt_path, out_dir, expand_data, max_data_cols)\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;124;03mConvert concatenated CSI text into an Excel .xlsx file.\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;124;03m    Absolute path to the saved .xlsx file.\u001B[39;00m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;66;03m# Read the entire file\u001B[39;00m\n\u001B[1;32m---> 32\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(txt_path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m, encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m     33\u001B[0m     content \u001B[38;5;241m=\u001B[39m f\u001B[38;5;241m.\u001B[39mread()\n\u001B[0;32m     35\u001B[0m \u001B[38;5;66;03m# Normalize escaped newlines in case the file is one long line like \"...]\\nCSI_DATA...\"\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001B[0m, in \u001B[0;36m_modified_open\u001B[1;34m(file, *args, **kwargs)\u001B[0m\n\u001B[0;32m    317\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[0;32m    318\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    319\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    320\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    321\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    322\u001B[0m     )\n\u001B[1;32m--> 324\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m io_open(file, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'csi1/15-41-51-299.txt'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import zscore\n",
    "import os\n",
    "\n",
    "paths = ['csi1/15-41-51-299']\n",
    "for inumber,i in enumerate(paths):\n",
    "    file_path = f\"{i}.xlsx\"\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    print(\"Shape:\", df.shape)\n",
    "    print(df.head())\n",
    "\n",
    "    # ===== 2. پردازش ستون Data =====\n",
    "    # جدا کردن رشته به لیست اعداد\n",
    "    df[\"Data_list\"] = df[\"Data\"].apply(lambda x: np.array([int(i) for i in str(x).split(\",\") if i.strip() != \"\"]))\n",
    "\n",
    "    # پیدا کردن طول بیشینه\n",
    "    max_len = df[\"Data_list\"].apply(len).max()\n",
    "\n",
    "    # نرمال کردن طول آرایه‌ها (padding با NaN)\n",
    "    data_matrix = np.array([\n",
    "        np.pad(arr.astype(float), (0, max_len - len(arr)), constant_values=np.nan)\n",
    "        for arr in df[\"Data_list\"]\n",
    "    ])\n",
    "\n",
    "    # ساخت دیتافریم عددی\n",
    "    df_expanded = pd.DataFrame(data_matrix)\n",
    "\n",
    "    print(\"\\nExpanded shape:\", df_expanded.shape)\n",
    "\n",
    "    # ===== 3. محاسبات آماری =====\n",
    "    stats = df_expanded.describe().T\n",
    "    stats[\"variance\"] = df_expanded.var(skipna=True)\n",
    "    print(\"\\n=== Statistical Summary (first 10 features) ===\\n\", stats.head(10))\n",
    "\n",
    "    # ===== 4. شناسایی Outliers =====\n",
    "    z_scores = np.abs(zscore(df_expanded, nan_policy='omit'))\n",
    "    outliers = (z_scores > 3).sum(axis=0)\n",
    "    print(\"\\nNumber of outliers in each feature (first 10 cols):\\n\", outliers[:10])\n",
    "\n",
    "    # ===== 5. ترسیم نمودار برای هر کانال (با 3 ساب‌پلات) =====\n",
    "    output_dir = \"plots_all_channels\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for col in df_expanded.columns:\n",
    "        channel_data = df_expanded[col].dropna()\n",
    "\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 4))\n",
    "\n",
    "        # --- Histogram ---\n",
    "        axes[0].hist(channel_data, bins=30, color=\"skyblue\", edgecolor=\"black\")\n",
    "        axes[0].set_title(f\"Histogram - Channel {col}\")\n",
    "        axes[0].set_xlabel(\"Value\")\n",
    "        axes[0].set_ylabel(\"Frequency\")\n",
    "\n",
    "        # --- Boxplot ---\n",
    "        sns.boxplot(x=channel_data, ax=axes[1], color=\"lightcoral\")\n",
    "        axes[1].set_title(f\"Boxplot - Channel {col}\")\n",
    "        axes[1].set_xlabel(\"Value\")\n",
    "\n",
    "        # --- Line plot ---\n",
    "        axes[2].plot(channel_data, color=\"navy\")\n",
    "        axes[2].set_title(f\"Time Series - Channel {col}\")\n",
    "        axes[2].set_xlabel(\"Index\")\n",
    "        axes[2].set_ylabel(\"Value\")\n",
    "\n",
    "        plt.suptitle(f\"Channel {col} - Data Analysis\", fontsize=14)\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.savefig(os.path.join(output_dir, f\"channel_{col}_{inumber}_analysis.png\"))\n",
    "        print(inumber)\n",
    "        plt.close()\n",
    "\n",
    "    print(f\"\\n✅ All combined plots saved in folder: {output_dir}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-14T15:15:23.713913Z",
     "start_time": "2025-09-14T15:15:23.337050Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'csi1/15-41-51-299.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 11\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m inumber,i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(paths):\n\u001B[0;32m     10\u001B[0m     file_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.xlsx\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m---> 11\u001B[0m     df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_excel(file_path)\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShape:\u001B[39m\u001B[38;5;124m\"\u001B[39m, df\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;28mprint\u001B[39m(df\u001B[38;5;241m.\u001B[39mhead())\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001B[0m, in \u001B[0;36mread_excel\u001B[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001B[0m\n\u001B[0;32m    493\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(io, ExcelFile):\n\u001B[0;32m    494\u001B[0m     should_close \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 495\u001B[0m     io \u001B[38;5;241m=\u001B[39m ExcelFile(\n\u001B[0;32m    496\u001B[0m         io,\n\u001B[0;32m    497\u001B[0m         storage_options\u001B[38;5;241m=\u001B[39mstorage_options,\n\u001B[0;32m    498\u001B[0m         engine\u001B[38;5;241m=\u001B[39mengine,\n\u001B[0;32m    499\u001B[0m         engine_kwargs\u001B[38;5;241m=\u001B[39mengine_kwargs,\n\u001B[0;32m    500\u001B[0m     )\n\u001B[0;32m    501\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m engine \u001B[38;5;129;01mand\u001B[39;00m engine \u001B[38;5;241m!=\u001B[39m io\u001B[38;5;241m.\u001B[39mengine:\n\u001B[0;32m    502\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    503\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEngine should not be specified when passing \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    504\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124man ExcelFile - ExcelFile already has the engine set\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    505\u001B[0m     )\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1550\u001B[0m, in \u001B[0;36mExcelFile.__init__\u001B[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001B[0m\n\u001B[0;32m   1548\u001B[0m     ext \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxls\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1549\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1550\u001B[0m     ext \u001B[38;5;241m=\u001B[39m inspect_excel_format(\n\u001B[0;32m   1551\u001B[0m         content_or_path\u001B[38;5;241m=\u001B[39mpath_or_buffer, storage_options\u001B[38;5;241m=\u001B[39mstorage_options\n\u001B[0;32m   1552\u001B[0m     )\n\u001B[0;32m   1553\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ext \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1554\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1555\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExcel file format cannot be determined, you must specify \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1556\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124man engine manually.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1557\u001B[0m         )\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1402\u001B[0m, in \u001B[0;36minspect_excel_format\u001B[1;34m(content_or_path, storage_options)\u001B[0m\n\u001B[0;32m   1399\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(content_or_path, \u001B[38;5;28mbytes\u001B[39m):\n\u001B[0;32m   1400\u001B[0m     content_or_path \u001B[38;5;241m=\u001B[39m BytesIO(content_or_path)\n\u001B[1;32m-> 1402\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m get_handle(\n\u001B[0;32m   1403\u001B[0m     content_or_path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m, storage_options\u001B[38;5;241m=\u001B[39mstorage_options, is_text\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m   1404\u001B[0m ) \u001B[38;5;28;01mas\u001B[39;00m handle:\n\u001B[0;32m   1405\u001B[0m     stream \u001B[38;5;241m=\u001B[39m handle\u001B[38;5;241m.\u001B[39mhandle\n\u001B[0;32m   1406\u001B[0m     stream\u001B[38;5;241m.\u001B[39mseek(\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:882\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    873\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\n\u001B[0;32m    874\u001B[0m             handle,\n\u001B[0;32m    875\u001B[0m             ioargs\u001B[38;5;241m.\u001B[39mmode,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    878\u001B[0m             newline\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    879\u001B[0m         )\n\u001B[0;32m    880\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    881\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m--> 882\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n\u001B[0;32m    883\u001B[0m     handles\u001B[38;5;241m.\u001B[39mappend(handle)\n\u001B[0;32m    885\u001B[0m \u001B[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001B[39;00m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'csi1/15-41-51-299.xlsx'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def csi_txt_to_excel(txt_path, out_dir=None, expand_data=False, max_data_cols=0):\n",
    "    \"\"\"\n",
    "    Convert concatenated CSI text into an Excel .xlsx file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    txt_path : str\n",
    "        Path to the input .txt file.\n",
    "    out_dir : str or None\n",
    "        Writable directory for the output .xlsx. If None, the function auto-selects:\n",
    "        - same directory as txt_path if writable\n",
    "        - '/kaggle/working' if available and writable\n",
    "        - current working directory otherwise\n",
    "    expand_data : bool\n",
    "        If True, expand the values inside data=[...] into separate columns (Data0, Data1, ...).\n",
    "        If False, keep the full list as a single string in column 'Data'.\n",
    "    max_data_cols : int\n",
    "        Max number of data columns to create when expand_data=True.\n",
    "        0 means auto-cap to Excel's column limit (up to 16,384 minus metadata columns).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Absolute path to the saved .xlsx file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Read the entire file\n",
    "    with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # Normalize escaped newlines in case the file is one long line like \"...]\\nCSI_DATA...\"\n",
    "    content = content.replace(\"\\\\n\", \"\\n\")\n",
    "\n",
    "    # Split into records; keep 'CSI_DATA,' at the start of each chunk\n",
    "    chunks = re.split(r'(?=CSI_DATA,)', content)\n",
    "    rows = []\n",
    "\n",
    "    for rec in chunks:\n",
    "        rec = rec.strip()\n",
    "        if not rec.startswith(\"CSI_DATA,\"):\n",
    "            continue\n",
    "\n",
    "        # Extract MAC: token right after \"CSI_DATA,\"\n",
    "        m_mac = re.search(r'^CSI_DATA,([^,]+)', rec)\n",
    "        mac = m_mac.group(1).strip() if m_mac else \"\"\n",
    "\n",
    "        # Extract timestamp after \"Now=\"\n",
    "        m_time = re.search(r'Now=\\s*([0-9\\-]{10}\\s[0-9:\\.]{8,})', rec)\n",
    "        timestamp = m_time.group(1).strip() if m_time else \"\"\n",
    "\n",
    "        # Extract data list inside brackets\n",
    "        m_data = re.search(r'data=\\[([^\\]]*)\\]', rec)\n",
    "        data_str = m_data.group(1).strip() if m_data else \"\"\n",
    "        data_list = [s.strip() for s in data_str.split(\",\")] if data_str else []\n",
    "\n",
    "        row = {\"MAC\": mac, \"Timestamp\": timestamp, \"Data\": data_str}\n",
    "\n",
    "        if expand_data:\n",
    "            # Determine max columns we can safely create for Excel\n",
    "            if max_data_cols <= 0:\n",
    "                # Excel limit is 16,384 columns; we already have 3 meta columns\n",
    "                max_cols_possible = 16384 - 3\n",
    "            else:\n",
    "                max_cols_possible = max_data_cols\n",
    "\n",
    "            for i, val in enumerate(data_list[:max_cols_possible]):\n",
    "                row[f\"Data{i}\"] = val\n",
    "\n",
    "            # Inform if truncated\n",
    "            if len(data_list) > max_cols_possible:\n",
    "                row[\"Data_Truncated\"] = f\"{len(data_list) - max_cols_possible} values truncated\"\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    # Build DataFrame\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # Helper to test if a directory is writable\n",
    "    def is_writable(dirpath: str) -> bool:\n",
    "        try:\n",
    "            test_path = os.path.join(dirpath, \".write_test\")\n",
    "            with open(test_path, \"w\") as tmp:\n",
    "                tmp.write(\"ok\")\n",
    "            os.remove(test_path)\n",
    "            return True\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "    # Decide output directory\n",
    "    src_dir = os.path.dirname(os.path.abspath(txt_path))\n",
    "    if out_dir:\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        target_dir = out_dir\n",
    "    elif is_writable(src_dir):\n",
    "        target_dir = src_dir\n",
    "    elif os.path.isdir(\"/kaggle/working\") and is_writable(\"/kaggle/working\"):\n",
    "        target_dir = \"/kaggle/working\"\n",
    "    else:\n",
    "        target_dir = os.getcwd()\n",
    "\n",
    "    # Build output path\n",
    "    base_name = os.path.splitext(os.path.basename(txt_path))[0]\n",
    "    excel_path = os.path.join(target_dir, 'xl')\n",
    "    excel_path = os.path.join(excel_path, base_name + \".xlsx\")\n",
    "\n",
    "    # Save to Excel\n",
    "    df.to_excel(excel_path, index=False)\n",
    "    return os.path.abspath(excel_path)\n",
    "\n",
    "def convert_all_txt_in_folders(root_folders, expand_data=False, max_data_cols=0):\n",
    "    \"\"\"\n",
    "    Convert all .txt files inside given folders to .xlsx files using csi_txt_to_excel,\n",
    "    saving each Excel file in the same folder as the original .txt file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    root_folders : list of str\n",
    "        List of folder paths containing .txt files to convert.\n",
    "    expand_data : bool\n",
    "        Passed to csi_txt_to_excel to control data expansion.\n",
    "    max_data_cols : int\n",
    "        Passed to csi_txt_to_excel for max data columns if expand_data=True.\n",
    "    \"\"\"\n",
    "    for folder in tqdm(root_folders):\n",
    "        for dirpath, _, filenames in os.walk(folder):\n",
    "            for filename in filenames:\n",
    "                if filename.lower().endswith('.txt'):\n",
    "                    txt_path = os.path.join(dirpath, filename)\n",
    "                    # print(f\"Converting: {txt_path}\")\n",
    "                    out_path = csi_txt_to_excel(txt_path, out_dir=dirpath,\n",
    "                                                expand_data=expand_data,\n",
    "                                                max_data_cols=max_data_cols)\n",
    "                    # print(f\"✅ Saved to: {out_path}\")\n",
    "\n",
    "folders = [\n",
    "    r\"D:\\Mojtaba\\Dataset_Master_minds\\DataSet_test\\csi1\",\n",
    "    r\"D:\\Mojtaba\\Dataset_Master_minds\\DataSet_test\\csi2\",\n",
    "    r\"D:\\Mojtaba\\Dataset_Master_minds\\DataSet_test\\csi3\",\n",
    "    r\"D:\\Mojtaba\\Dataset_Master_minds\\DataSet_test\\csi4\"\n",
    "]\n",
    "\n",
    "convert_all_txt_in_folders(folders)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-14T15:15:32.054859Z",
     "start_time": "2025-09-14T15:15:32.024371Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 7446.61it/s]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import zscore\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "folders = [\n",
    "    r\"DataSet_test\\csi1\\xl\",\n",
    "    r\"DataSet_test\\csi2\\xl\",\n",
    "    r\"DataSet_test\\csi3\\xl\",\n",
    "    r\"DataSet_test\\csi4\\xl\"\n",
    "]\n",
    "\n",
    "for folder in tqdm(folders, desc=\"Folders\", unit=\"folder\"):\n",
    "    # پیدا کردن همه فایل‌های xlsx داخل این فولدر (و زیر‌فولدرها)\n",
    "    xlsx_paths = []\n",
    "    for dirpath, _, filenames in os.walk(folder):\n",
    "        for fn in filenames:\n",
    "            if fn.lower().endswith('.xlsx'):\n",
    "                xlsx_paths.append(os.path.join(dirpath, fn))\n",
    "\n",
    "    if len(xlsx_paths) == 0:\n",
    "        tqdm.write(f\"No .xlsx files found in: {folder}\")\n",
    "        continue\n",
    "\n",
    "    # فقط 1 نمونه (فایل) از هر پوشه بردار\n",
    "    xlsx_paths = xlsx_paths[:1]\n",
    "\n",
    "    # نوار پیشرفت برای فایل‌های انتخاب‌شده\n",
    "    for file_idx, xlsx_path in enumerate(tqdm(xlsx_paths, desc=f\"Files in {os.path.basename(folder)}\", leave=False, unit=\"file\")):\n",
    "        filename = os.path.basename(xlsx_path)\n",
    "        dirpath = os.path.dirname(xlsx_path)\n",
    "\n",
    "        df = pd.read_excel(xlsx_path)\n",
    "\n",
    "        # ===== 2. پردازش ستون Data =====\n",
    "        df[\"Data_list\"] = df[\"Data\"].apply(lambda x: np.array([int(i) for i in str(x).split(\",\") if i.strip() != \"\"]))\n",
    "\n",
    "        max_len = df[\"Data_list\"].apply(len).max()\n",
    "\n",
    "        data_matrix = np.array([\n",
    "            np.pad(arr.astype(float), (0, max_len - len(arr)), constant_values=np.nan)\n",
    "            for arr in df[\"Data_list\"]\n",
    "        ])\n",
    "\n",
    "        df_expanded = pd.DataFrame(data_matrix)\n",
    "\n",
    "        # ===== 3. محاسبات آماری =====\n",
    "        stats = df_expanded.describe().T\n",
    "        stats[\"variance\"] = df_expanded.var(skipna=True)\n",
    "\n",
    "        # ===== 4. شناسایی Outliers =====\n",
    "        z_scores = np.abs(zscore(df_expanded, nan_policy='omit'))\n",
    "        outliers = (z_scores > 3).sum(axis=0)\n",
    "\n",
    "        # ===== 5. ترسیم نمودار =====\n",
    "        output_dir = os.path.join(dirpath, 'plots')\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # تعداد جفت کانال = ceil(total_channels / 2)\n",
    "        n_pairs = (df_expanded.shape[1] + 1) // 2\n",
    "\n",
    "        # tqdm برای هر جفت کانال — با total قابل نمایش ETA\n",
    "        for pair_num in tqdm(range(n_pairs),\n",
    "                             desc=f\"File {file_idx+1}/{len(xlsx_paths)}: {filename}\",\n",
    "                             leave=False,\n",
    "                             unit=\"pair\"):\n",
    "            i = pair_num * 2  # کانال real شروع\n",
    "            fig, axes = plt.subplots(2, 3, figsize=(18, 8))\n",
    "\n",
    "            for j in range(2):  # 0 = real, 1 = imag\n",
    "                col = i + j\n",
    "                if col >= df_expanded.shape[1]:\n",
    "                    # اگر تعداد کانال‌ها فرد بود ممکنه اینجا از حدود بیرون بزنه؛ ادامه بده\n",
    "                    for empty_ax in axes[j]:\n",
    "                        empty_ax.axis('off')\n",
    "                    continue\n",
    "\n",
    "                channel_data = df_expanded[col].dropna()\n",
    "\n",
    "                # اگر داده‌ای نبود، محتوای خالی بذار\n",
    "                if channel_data.size == 0:\n",
    "                    for ax in axes[j]:\n",
    "                        ax.text(0.5, 0.5, \"No data\", ha='center', va='center', transform=ax.transAxes)\n",
    "                        ax.set_axis_off()\n",
    "                    continue\n",
    "\n",
    "                mean_val = stats.loc[col, \"mean\"]\n",
    "                var_val = stats.loc[col, \"variance\"]\n",
    "\n",
    "                # --- Histogram ---\n",
    "                axes[j, 0].hist(channel_data, bins=30, edgecolor=\"black\")\n",
    "                axes[j, 0].axvline(mean_val, color=\"red\", linestyle=\"--\", label=f\"Mean={mean_val:.2f}\")\n",
    "                axes[j, 0].legend()\n",
    "                axes[j, 0].set_title(f\"Histogram - Channel {col}\\nVariance={var_val:.2f}\")\n",
    "                axes[j, 0].set_xlabel(\"Value\")\n",
    "                axes[j, 0].set_ylabel(\"Frequency\")\n",
    "\n",
    "                # --- Boxplot ---\n",
    "                sns.boxplot(x=channel_data, ax=axes[j, 1])\n",
    "                # اگر outliers[col] NaN بود، نمایش نده\n",
    "                try:\n",
    "                    out_count = int(outliers[col])\n",
    "                except Exception:\n",
    "                    out_count = 0\n",
    "                axes[j, 1].set_title(f\"Boxplot - Channel {col}\\nOutliers={out_count}\")\n",
    "                axes[j, 1].set_xlabel(\"Value\")\n",
    "\n",
    "                # --- Line plot ---\n",
    "                axes[j, 2].plot(channel_data)\n",
    "                axes[j, 2].set_title(f\"Time Series - Channel {col}\")\n",
    "                axes[j, 2].set_xlabel(\"Index\")\n",
    "                axes[j, 2].set_ylabel(\"Value\")\n",
    "                axes[j, 2].text(0.01, 0.95,\n",
    "                                f\"Mean={mean_val:.2f}\\nMin={channel_data.min():.2f}\\nMax={channel_data.max():.2f}\",\n",
    "                                transform=axes[j, 2].transAxes,\n",
    "                                fontsize=9, verticalalignment='top',\n",
    "                                bbox=dict(facecolor='white', alpha=0.6))\n",
    "\n",
    "            plt.suptitle(f\"Channels {i} (Real) & {i+1} (Imag) - Data Analysis\", fontsize=14)\n",
    "            plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "            out_fname = os.path.join(output_dir, f\"channels_{i}_{i+1}_analysis.png\")\n",
    "            plt.savefig(out_fname)\n",
    "            plt.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-09-14T15:20:13.459544Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folders:   0%|          | 0/4 [00:00<?, ?folder/s]\n",
      "Files in xl:   0%|          | 0/1 [00:00<?, ?file/s]\u001B[A\n",
      "\n",
      "File 1/1: 15-41-51-299.xlsx:   0%|          | 0/64 [00:00<?, ?pair/s]\u001B[A\u001B[A\n",
      "\n",
      "File 1/1: 15-41-51-299.xlsx:   2%|▏         | 1/64 [00:01<01:04,  1.02s/pair]\u001B[A\u001B[A\n",
      "\n",
      "File 1/1: 15-41-51-299.xlsx:   3%|▎         | 2/64 [00:01<00:58,  1.06pair/s]\u001B[A\u001B[A\n",
      "\n",
      "File 1/1: 15-41-51-299.xlsx:   5%|▍         | 3/64 [00:02<00:55,  1.11pair/s]\u001B[A\u001B[A"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
